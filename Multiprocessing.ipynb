{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a31bc32-9d23-4b72-8e8b-ac5e2a21905e",
   "metadata": {},
   "source": [
    "Q1. What is multiprocessing in python? Why is it useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ac777-2c6e-4639-af34-498b5b9b922b",
   "metadata": {},
   "source": [
    "Multiprocessing in Python refers to the concurrent execution of multiple processes, each with its own Python interpreter. Unlike multithreading, which involves multiple threads within a single process sharing the same memory space and the Global Interpreter Lock (GIL) limitation, multiprocessing takes advantage of multiple CPU cores and separate memory spaces.\n",
    "\n",
    "Reasons why multiprocessing is useful in Python:\n",
    "\n",
    "Parallelism: Multiprocessing allows you to achieve true parallelism, where multiple processes run independently and simultaneously, making efficient use of modern multicore processors. This results in significantly improved performance for CPU-bound tasks.\n",
    "\n",
    "GIL Bypass: Unlike multithreading, each Python process spawned in multiprocessing has its own Python interpreter and memory space. Therefore, it bypasses the GIL limitation, making it suitable for computationally intensive tasks.\n",
    "\n",
    "Scalability: Multiprocessing can be used to scale up the performance of applications by taking advantage of the available hardware resources. It's particularly useful in scientific computing, data analysis, and simulations where computation speed is crucial.\n",
    "\n",
    "Fault Isolation: In multiprocessing, each process runs in its own memory space. If one process crashes due to an error, it typically doesn't affect the other processes, enhancing program robustness.\n",
    "\n",
    "Improved Performance: By dividing a large task into smaller subprocesses that run in parallel, multiprocessing can significantly reduce the execution time of complex computations.\n",
    "\n",
    "Task Distribution: Multiprocessing enables the distribution of tasks across multiple processes, making it possible to tackle large-scale problems efficiently.\n",
    "\n",
    "Resource Utilization: It allows efficient utilization of all available CPU cores, leading to better resource management and reduced execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a3ab8-00eb-4333-83a3-26559ee7cfdd",
   "metadata": {},
   "source": [
    "Q2. What are the differences between multiprocessing and multithreading?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51494dc-5936-47b3-9e72-909ff457fd42",
   "metadata": {},
   "source": [
    "Multiprocessing: It involves running multiple processes, each with its own separate memory space and Python interpreter. Processes can run independently, making full use of multiple CPU cores. Efficiently utilizes multiple CPU cores or processors, making it suitable for CPU-bound tasks. Provides process isolation; if one process crashes, it typically doesn't affect others. Processes have separate memory spaces.Achieves a higher level of concurrency as each process runs independently. Well-suited for parallelism.Communication between processes is achieved through mechanisms like pipes, queues, and shared memory.Can be more complex to set up due to inter-process communication mechanisms. Processes don't share memory by default.Bypasses the GIL since each process has its own Python interpreter.\n",
    "\n",
    "Multithreading: It involves running multiple threads within a single process. Threads share the same memory space and Python interpreter but may run concurrently. Limited by the Global Interpreter Lock in C ython, so it's less effective for CPU-bound tasks. Better suited for I/O-bound tasks where threads spend time waiting for input/output operations.Threads within the same process share the same memory space, so issues in one thread can potentially affect others. Achieves a lower level of concurrency due to the GIL restriction. Better suited for concurrent I/O operations.Threads can communicate more easily through shared data structures, but this requires careful synchronization to avoid race conditions.Generally simpler to implement as threads share memory by default, but it requires careful synchronization to avoid race conditions.Affected by the GIL, limiting true parallelism for CPU-bound tasks in C Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417bc85-bc3a-4774-8dc3-c6e9e68ca5e4",
   "metadata": {},
   "source": [
    "Q3. Write a python code to create a process using the multiprocessing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe11ac8-c920-4c9e-a90f-6fdd2bc72cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker process is running.\n",
      "Main process continues.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def worker_function():\n",
    "    print(\"Worker process is running.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a Process object\n",
    "    worker_process = multiprocessing.Process(target=worker_function)\n",
    "\n",
    "    worker_process.start()\n",
    "\n",
    "    worker_process.join()\n",
    "\n",
    "    print(\"Main process continues.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85b2a7-1a63-4d46-9340-73fb17c3df50",
   "metadata": {},
   "source": [
    "Q4. What is a multiprocessing pool in python? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269824f2-a571-4ea9-a9e8-a8902de0a6fe",
   "metadata": {},
   "source": [
    "A multiprocessing pool in Python, often provided by the multiprocessing.Pool class, is a high-level abstraction for managing and distributing tasks across multiple processes, typically to leverage the full capabilities of a multi-core CPU or processor. It is used for parallelizing and distributing the execution of functions or tasks across a pool of worker processes, making it easier to achieve concurrent execution of tasks and improve performance for CPU-bound operations.\n",
    "\n",
    "Key features and purposes of multiprocessing pools:\n",
    "\n",
    "Parallel Execution: A pool divides the tasks into smaller units and assigns them to available worker processes. This allows tasks to be executed concurrently, utilizing multiple CPU cores effectively.\n",
    "\n",
    "Simplified API: Pools provide a simple and high-level API for parallelism, allowing developers to parallelize tasks without manually managing individual processes.\n",
    "\n",
    "Task Distribution: Pools distribute tasks across available processes, managing the creation and termination of worker processes as needed.\n",
    "\n",
    "Result Collection: Pools can collect results from worker processes, making it easy to retrieve the results of parallel computations.\n",
    "\n",
    "Efficiency: Pools are efficient in managing processes and reusing them for multiple tasks, reducing the overhead associated with process creation and destruction.\n",
    "\n",
    "Control: Pools offer control over the number of worker processes created, making it possible to optimize performance based on the available hardware resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5c697-b150-47f8-ba96-d51ba11262b0",
   "metadata": {},
   "source": [
    "Q5. How can we create a pool of worker processes in python using the multiprocessing module?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc7cf0-2bc6-4101-bd52-1853d23ce0d9",
   "metadata": {},
   "source": [
    "You can create a pool of worker processes in Python using the multiprocessing module by using the multiprocessing.Pool class. Here's a step-by-step guide on how to do it:\n",
    "\n",
    "1.Import the multiprocessing module.\n",
    "2.Define the function that you want to parallelize. This function will be executed by the worker processes.\n",
    "3.In the if __name__== __main__: block create a pool of worker processes using multiprocessing.Pool.\n",
    "4.Replace your_function with the actual function you want to parallelize and arguments with the list of arguments you want to pass to the function. The pool.map method parallelizes the execution of your_function with the provided arguments and collects the results in the results list.\n",
    "5.After the with block, you can access the results obtained from the worker processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7eb76-aa3b-49fc-b481-ae4dcb062bc3",
   "metadata": {},
   "source": [
    "Q6. Write a python program to create 4 processes, each process should print a different number using the\n",
    "multiprocessing module in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb48837b-3e86-4da6-ae0c-d71c5a6f75d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1: 1\n",
      "Process 2: 2\n",
      "Process 3: 3\n",
      "Process 4: 4\n",
      "Processes have completed.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def print_number(number):\n",
    "    print(f\"Process {number}: {number}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processes = []\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        process = multiprocessing.Process(target=print_number, args=(i,))\n",
    "        processes.append(process)\n",
    "\n",
    "    for process in processes:\n",
    "        process.start()\n",
    "\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    print(\"Processes have completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
